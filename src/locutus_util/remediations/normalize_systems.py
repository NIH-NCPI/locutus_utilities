#!/usr/bin/env python3
'''
This script is for updating improper systems(existing_ontologies) into actual
systems via a lookup table generated/transformed in the 'ontology_api_etl.py' 
script. If missing systems entirely, run backfill_missing_systems.py instead. 
That script will search for the codes using search-dragon, this script is a 
string replacement.

Suggestion: Uncomment lines ~59-30 while doing initial troubleshooting/setup. Also,
any runs of get_distinct_mapping_systems. This function will also crawl through
the db. Try not to run when it is not needed, to keep down hits to the db.

Searches the Terminology Collections mappings, collecting doc references to update.
Prints a csv of edits to review before performing the update.
    Search for UNKNOWN in the csv, for any issues
After update confirmation, replaces the systems in the docs referenced.
Log will print for confirmation. 
    Check for error messages, and/or run again to scan.
    Check the file named *_existing_systems.csv(generated by get_distinct_mapping_systems.py)
    for all systems still in the db.

Suggestion: Place both printouts in the ticket for documentation
'''

import argparse
import pandas as pd
from google.cloud import firestore
import logging
from datetime import datetime
from locutus_util.common import LOGS_PATH, ONTOLOGY_API_PATH
from locutus_util.helpers import (set_logging_config, write_file)
from locutus.model.ontologies_search import OntologyAPISearchModel
from locutus_util.analysis.get_distinct_mapping_systems import main as get_distinct_mapping_systems


existing_ontologies = systems_list = [
    "BTO", "CL", "CLO", "EMAPA",
    "ExO", "FMA", "HP", "HPO",
    "LEPAO", "LOINC", "MA", "OMIM",
    "MONDO", "MSH", "MeSH", "NCIT",
    "NCRO", "OARCS", "OBA", "OMIM",
    "OMIT", "ORPHANET", "SNOMED", "SO",
    "UBERON", "UK Biobank", "XAO", "ZFA",
    "MIM", "ORDO"
]


def scan(db, ontology_lookup):
    """
    Scans the 'mappings' subcollection of all documents in 'Terminology',
    and returns a list of codes that are missing the 'system' field or have it null/empty.
    """
    missing_system_entries = []

    term_docs = db.collection("Terminology").list_documents()
    total_missing = 0

    for term_doc in term_docs:
        term_id = term_doc.id
        mappings_ref = term_doc.collection("mappings")
        # if total_missing >= 10:
        #     continue
        for mapping_doc in mappings_ref.stream():
            data = mapping_doc.to_dict()
            codes = data.get("codes", [])
            for code_entry in codes:
                system = code_entry.get("system")
                if system in existing_ontologies:
                    proposed_system = propose_system_for_code(system,ontology_lookup)
                    mapping_dict = {
                        "terminology_id": term_id,
                        "mapping_id": mapping_doc.id,
                        "code": code_entry.get("code"),
                        "display": code_entry.get("display"),
                        "system": system,
                        "proposed_system": proposed_system
                    }
                    missing_system_entries.append(mapping_dict)
                    total_missing += 1
                    logging.info(f"Mapping missing proposed_system: {mapping_dict}")
    logging.info(f"Total missing system entries: {total_missing}")

    return missing_system_entries

def build_system_lookup(ontology_lookup):
    """
    Builds a dictionary from the lookup table for fast curie-to-system lookup.
    """
    return {
        str(row['curie']).strip(): str(row['system']).strip()
        for _, row in ontology_lookup.iterrows()
        if pd.notna(row['curie']) and pd.notna(row['system'])
    }


def propose_system_for_code(db_system, ontology_lookup):
    """
    Proposes a system based on known curies and patterns.
    """
    if not db_system:
        return None
    
    # These ontologies short codes are not in the lookup as they are, require additional mapping
    map = {
        "LOINC": "LNC",
        "MIM": "OMIM",
        "MeSH": "MSH",
        "MESH": "MSH",
        "ORDO": "OMIM",
    }

    for db_sys, lookup_sys in map.items():
        if db_system == db_sys:
            db_system = lookup_sys

    # If the current system is found(exact match) to an ontology in the lookup,
    # then return the system for that ontology.
    if db_system in ontology_lookup:
        return ontology_lookup[db_system]

    return "UNKNOWN"


def update_mapping_systems(db, entries):
    """
    Updates Firestore mapping documents with the proposed system values.
    """
    updated_count = 0
    for entry in entries:
        term_id = entry["terminology_id"]
        mapping_id = entry["mapping_id"]
        code_to_update = entry["code"]
        proposed_system = entry["proposed_system"]

        if not all([term_id, mapping_id, code_to_update, proposed_system]) or proposed_system == "UNKNOWN":
            logging.warning(f"Skipping incomplete entry: {entry}")
            continue

        mapping_ref = db.collection("Terminology").document(term_id).collection("mappings").document(mapping_id)
        mapping_data = mapping_ref.get().to_dict()

        if not mapping_data:
            logging.warning(f"Mapping document not found: {term_id}/{mapping_id}")
            continue

        codes = mapping_data.get("codes", [])
        updated = False
        for code_entry in codes:
            if code_entry.get("code") == code_to_update:
                code_entry["system"] = proposed_system
                updated = True

        if updated:
            try:
                mapping_ref.update({"codes": codes})
                updated_count += 1
                logging.info(f"Updated mapping: {term_id}/{mapping_id} with system {proposed_system}")
            except Exception as e:
                logging.error(f"Failed to update mapping {term_id}/{mapping_id}: {e}")

    logging.info(f"Updated {updated_count} mappings with proposed systems.")

def main(project_id,database):
            
    # Set log filepaths. Tests in dev will overwrite themselves
    _log_file = f"{LOGS_PATH}/{datetime.now().strftime('%Y%m%d_%H%M%S')}_{project_id}_{database}_system_remediation.log"
    issue_log_path = f"{LOGS_PATH}/{datetime.now().strftime('%Y%m%d_%H%M%S')}_{project_id}_{database}_missing_sys.csv"
    if project_id.endswith("dev"):
        _log_file = f"{LOGS_PATH}/{datetime.now().strftime('%m%d')}_{project_id}_{database}_system_remediation.log"
        issue_log_path = f"{LOGS_PATH}/{datetime.now().strftime('%m%d')}_{project_id}_{database}_missing_sys.csv"

    # Set logging configs -log file created in data/logs
    set_logging_config(log_file = _log_file)

    # Initiate Firestore client and setting the project_id
    db = firestore.Client(project=project_id, database=database)
    
    onto_file = pd.read_csv(ONTOLOGY_API_PATH)
    ontology_lookup = build_system_lookup(onto_file)

    # Find the mappings without systems, proposes systems where possible via the code prefix
    empty_systems = scan(db, ontology_lookup)

    if not empty_systems:
        logging.info("No mappings without systems found.")
        return


    logging.info(f"\nFound {len(empty_systems)} invalid mappings. See: {LOGS_PATH}")
    # get_distinct_mapping_systems(project_id, database)


    # Writes a file to review the proposed mappings before running the update.
    write_file(issue_log_path, empty_systems, ["code","mapping_id"])

    confirm = input("Update these mappings? [y/N]: ").strip().lower()

    if confirm == "y":
        update_mapping_systems(db, empty_systems)
        get_distinct_mapping_systems(project_id, database)

    else:
        logging.info("Update declined.")

if __name__ == "__main__":
    # TODO: Separate the jobs so you don't have to hit the db everytime you troubleshoot. For now, limit the scan to reduce cost.
    
    parser = argparse.ArgumentParser(description="Delete Terminology documents with slashes in their index.")
    parser.add_argument('-p', '--project_id', required=True, help="GCP Project to edit")
    parser.add_argument('-db', '--database', required=False, help="Database to edit. Will edit the projects default db if not set here.")


    args = parser.parse_args()
    

    main(project_id=args.project_id,database=args.database)
